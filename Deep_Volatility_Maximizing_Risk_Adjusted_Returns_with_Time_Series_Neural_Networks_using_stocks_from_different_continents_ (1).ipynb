{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Description**\n",
        "\n",
        "This notebook implements a  quantitative finance pipeline designed to construct a **Maximum Sharpe Ratio Portfolio** by leveraging an advanced **Hybrid Volatility Forecasting Model** over a diversified, multi-country (contintents) basket of financial sector stocks.\n",
        "\n",
        "The core strategy is to move beyond historical risk assessment by combining traditional econometrics with modern deep learning to predict future asset risk (variance), which is then used as the primary input for portfolio optimization.\n",
        "\n",
        "### **Key Methodology**\n",
        "\n",
        "1.  **Hybrid Risk Forecasting:**\n",
        "    * **GARCH(1,1):**\n",
        "    \n",
        "    Used to calculate the historical conditional variance (volatility-squared) of each asset's daily log returns.\n",
        "    \n",
        "    This GARCH variance serves as the **true risk signal (target variable)** for the neural network.\n",
        "\n",
        "\n",
        "    * **BiLSTM Model:**\n",
        "    \n",
        "    A Bidirectional Long Short-Term Memory network is trained on historical log returns to forecast the **future GARCH conditional variance**.\n",
        "    \n",
        "    This structure is highly effective for capturing complex, non-linear, and time-dependent patterns in financial time series.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "2.  **Portfolio Optimization:**\n",
        "    * **Predictive Covariance Matrix:**\n",
        "    \n",
        "    The BiLSTM's volatility forecast is combined with the historical correlation matrix to construct a forward-looking, annualized Covariance Matrix.\n",
        "\n",
        "\n",
        "    * **Maximum Sharpe Ratio:**\n",
        "    \n",
        "    The portfolio weights are optimized using the **SLSQP algorithm** to **Minimize the Negative Sharpe Ratio** (Maximize the Sharpe Ratio).\n",
        "\n",
        "\n",
        "    * **Diversification Constraints:**\n",
        "    \n",
        "    Practical constraints are enforced to ensure robust and diversified allocation, with asset weights bounded between **1% and 40%** ($0.01 \\le w_i \\le 0.40$).\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "\n",
        "The final comparison highlights the country-specific portfolio that yields the highest risk-adjusted return (Sharpe Ratio) based on the hybrid model's volatility predictions, providing an actionable strategy for capital allocation.\n",
        "\n",
        "**WARNING**:\n",
        "\n",
        "This notebook is not a financial advisor."
      ],
      "metadata": {
        "id": "YhvDA2ZZouDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install arch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFT-ARSJH8PP",
        "outputId": "fb45ab9a-2b24-4279-c40f-5277651b69b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from arch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from arch) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from arch) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from arch) (0.14.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arch) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->arch) (2025.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->arch) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->arch) (1.17.0)\n",
            "Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (981 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: arch\n",
            "Successfully installed arch-8.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from arch import arch_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Dropout, BatchNormalization\n",
        "from scipy.optimize import minimize\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "I5saZDJRhv-V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "START_DATE = \"2010-01-01\"\n",
        "END_DATE = \"2024-12-31\"\n",
        "LOOKBACK = 20\n",
        "FORECAST_HORIZON = 1\n",
        "RISK_FREE_RATE = 0.02\n",
        "ANNUALIZATION_FACTOR = 252\n",
        "\n",
        "\n",
        "TICKERS_BY_COUNTRY = {\n",
        "\n",
        "\n",
        "    \"UK\": [\"HSBA.L\", \"LLOY.L\", \"BARC.L\", \"NWG.L\", \"STAN.L\", \"AV.L\", \"LGEN.L\"],\n",
        "\n",
        "    \"France\": [\"BNP.PA\", \"GLE.PA\", \"ACA.PA\", \"CS.PA\", \"ML.PA\", \"SGO.PA\", \"CA.PA\"],\n",
        "\n",
        "\n",
        "    \"USA\": [\"JPM\", \"BAC\", \"WFC\", \"GS\", \"MS\", \"AXP\", \"C\"],\n",
        "\n",
        "\n",
        "    \"Australia\": [\"CBA.AX\", \"NAB.AX\", \"WBC.AX\", \"ANZ.AX\", \"MQG.AX\", \"SUN.AX\", \"AMP.AX\"],\n",
        "}\n",
        "\n",
        "ALL_TICKERS = [ticker for country in TICKERS_BY_COUNTRY.values() for ticker in country]\n",
        "\n",
        "\n",
        "\n",
        "def calculate_garch_volatility(series):\n",
        "\n",
        "\n",
        "    returns = np.log(series / series.shift(1)).dropna()\n",
        "\n",
        "    am = arch_model(returns * 100, vol='Garch', p=1, q=1, rescale=False)\n",
        "    try:\n",
        "        res = am.fit(update_freq=0, disp='off')\n",
        "\n",
        "        conditional_variance = (res.conditional_volatility**2) / (100**2)\n",
        "        return pd.Series(conditional_variance, index=returns.index)\n",
        "    except Exception:\n",
        "\n",
        "        return pd.Series(np.nan, index=returns.index)\n",
        "\n",
        "def portfolio_volatility(weights, cov_matrix):\n",
        "\n",
        "    port_variance = weights.T @ cov_matrix @ weights\n",
        "\n",
        "    epsilon = 1e-10\n",
        "    return np.sqrt(max(0, port_variance) + epsilon)\n",
        "\n",
        "def portfolio_return(weights, expected_returns):\n",
        "\n",
        "    return weights.T @ expected_returns\n",
        "\n",
        "def negative_sharpe_ratio(weights, expected_returns, cov_matrix, risk_free_rate):\n",
        "\n",
        "    port_return = portfolio_return(weights, expected_returns)\n",
        "    port_volatility = portfolio_volatility(weights, cov_matrix)\n",
        "\n",
        "    if port_volatility < 1e-8:\n",
        "        return 1e9\n",
        "\n",
        "\n",
        "    sharpe_ratio = (port_return - risk_free_rate) / port_volatility\n",
        "    return -sharpe_ratio\n",
        "\n",
        "\n",
        "\n",
        "def build_bilstm_model(lookback, n_features):\n",
        "\n",
        "    input_tensor = Input(shape=(lookback, n_features), name='Input_Layer')\n",
        "\n",
        "    x = Bidirectional(LSTM(units=128, return_sequences=True, name='BiLSTM_1',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)))(input_tensor)\n",
        "    x = BatchNormalization(name='BatchNorm_1')(x)\n",
        "    x = Dropout(0.3, name='Dropout_1')(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(units=64, return_sequences=False, name='BiLSTM_2',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)))(x)\n",
        "    x = BatchNormalization(name='BatchNorm_2')(x)\n",
        "    x = Dropout(0.3, name='Dropout_2')(x)\n",
        "\n",
        "    output_tensor = Dense(units=n_features, activation='linear', name='Output_Dense')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_and_sequence(data, volatility_data):\n",
        "\n",
        "\n",
        "    features = np.log(data / data.shift(1)).dropna()\n",
        "    targets = volatility_data.loc[features.index]\n",
        "    features = features.loc[targets.index]\n",
        "\n",
        "    if features.empty or targets.empty:\n",
        "        return None, None, None, None, None, None, None, None, None\n",
        "\n",
        "    N_FEATURES = features.shape[1]\n",
        "    TICKERS = features.columns.tolist()\n",
        "\n",
        "\n",
        "    feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_features = feature_scaler.fit_transform(features)\n",
        "    target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_targets = target_scaler.fit_transform(targets)\n",
        "\n",
        "\n",
        "    def create_sequences(features_arr, targets_arr, lookback, horizon):\n",
        "        X, Y = [], []\n",
        "        for i in range(len(features_arr) - lookback - horizon + 1):\n",
        "            X.append(features_arr[i:(i + lookback), :])\n",
        "            Y.append(targets_arr[i + lookback + horizon - 1, :])\n",
        "        return np.array(X), np.array(Y)\n",
        "\n",
        "    X, Y = create_sequences(scaled_features, scaled_targets, LOOKBACK, FORECAST_HORIZON)\n",
        "    train_size = int(len(X) * 0.8)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
        "\n",
        "\n",
        "    test_index = features.index[train_size + LOOKBACK + FORECAST_HORIZON - 1:]\n",
        "\n",
        "    return (X_train, Y_train, X_test, Y_test,\n",
        "            features, target_scaler, test_index, TICKERS, N_FEATURES)\n",
        "\n",
        "\n",
        "\n",
        "def optimize_portfolio(expected_returns, cov_matrix, tickers, risk_free_rate):\n",
        "\n",
        "    num_assets = len(tickers)\n",
        "    initial_weights = np.array([1/num_assets] * num_assets)\n",
        "\n",
        "\n",
        "    MIN_WEIGHT = 0.01\n",
        "    MAX_WEIGHT = 0.40\n",
        "\n",
        "\n",
        "    bounds = tuple([(MIN_WEIGHT, MAX_WEIGHT)] * num_assets)\n",
        "\n",
        "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
        "\n",
        "    optimal_results = minimize(\n",
        "        negative_sharpe_ratio,\n",
        "        initial_weights,\n",
        "        args=(expected_returns, cov_matrix, risk_free_rate),\n",
        "        method='SLSQP',\n",
        "        bounds=bounds,\n",
        "        constraints=constraints\n",
        "    )\n",
        "\n",
        "    if optimal_results.success:\n",
        "        optimal_weights = optimal_results.x\n",
        "        final_return = portfolio_return(optimal_weights, expected_returns)\n",
        "        final_volatility = portfolio_volatility(optimal_weights, cov_matrix)\n",
        "        final_sharpe = (final_return - risk_free_rate) / final_volatility\n",
        "\n",
        "\n",
        "        weights_df = pd.Series(optimal_weights, index=tickers)\n",
        "\n",
        "        top_weights_str = weights_df.sort_values(ascending=False).head(5).to_string(float_format='%.2f')\n",
        "    else:\n",
        "\n",
        "        final_return, final_volatility, final_sharpe = np.nan, np.nan, np.nan\n",
        "        top_weights_str = f\"Optimization failed: {optimal_results.message}\"\n",
        "\n",
        "    return {\n",
        "        'Return': final_return,\n",
        "        'Volatility': final_volatility,\n",
        "        'Sharpe': final_sharpe,\n",
        "        'Weights': top_weights_str,\n",
        "        'Status': optimal_results.message\n",
        "    }\n",
        "\n",
        "\n",
        "def main_analysis():\n",
        "    print(\"--- STARTING MULTI-COUNTRY QUANTITATIVE ANALYSIS (DIVERSIFIED) ---\\n\")\n",
        "    print(f\"1. Downloading and processing data from {START_DATE} to {END_DATE}...\")\n",
        "\n",
        "\n",
        "    all_tickers_list = list(set(ALL_TICKERS))\n",
        "    data = yf.download(all_tickers_list, start=START_DATE, end=END_DATE, progress=False)['Close']\n",
        "    data = data.ffill().bfill()\n",
        "\n",
        "    all_results = {}\n",
        "    best_sharpe = -np.inf\n",
        "    best_country = None\n",
        "\n",
        "    for country, tickers in TICKERS_BY_COUNTRY.items():\n",
        "        print(f\"\\n==================== PROCESSING: {country} ({len(tickers)} assets) ====================\\n\")\n",
        "\n",
        "\n",
        "        country_data = data[[t for t in tickers if t in data.columns]].dropna(axis=1)\n",
        "        country_tickers = country_data.columns.tolist()\n",
        "        N_FEATURES_COUNTRY = len(country_tickers)\n",
        "\n",
        "        if N_FEATURES_COUNTRY < 2:\n",
        "            print(f\"Skipping {country}: Not enough valid tickers ({N_FEATURES_COUNTRY}).\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        volatility_data = pd.DataFrame(index=country_data.index)\n",
        "        for ticker in country_tickers:\n",
        "            volatility_data[ticker] = calculate_garch_volatility(country_data[ticker])\n",
        "\n",
        "\n",
        "        volatility_data = volatility_data.ffill().bfill().dropna(axis=1)\n",
        "        country_tickers = volatility_data.columns.tolist()\n",
        "        country_data = country_data[country_tickers]\n",
        "        N_FEATURES_COUNTRY = len(country_tickers)\n",
        "\n",
        "        if N_FEATURES_COUNTRY < 2:\n",
        "            print(f\"Skipping {country}: Not enough valid tickers after GARCH filtering ({N_FEATURES_COUNTRY}).\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        results = preprocess_and_sequence(country_data, volatility_data)\n",
        "        if results is None or results[0].shape[0] == 0:\n",
        "            print(f\"Skipping {country}: Data sequencing failed.\")\n",
        "            continue\n",
        "\n",
        "        X_train, Y_train, X_test, Y_test, features, target_scaler, test_index, TICKERS_LIST, N_FEATURES_FINAL = results\n",
        "\n",
        "        print(f\"Data prepared. Final Tickers: {N_FEATURES_FINAL}. Test set size: {X_test.shape[0]}.\")\n",
        "\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "        bilstm_model = build_bilstm_model(LOOKBACK, N_FEATURES_FINAL)\n",
        "\n",
        "        history = bilstm_model.fit(\n",
        "            X_train, Y_train, epochs=30, batch_size=32,\n",
        "            validation_data=(X_test, Y_test), verbose=0,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True)]\n",
        "        )\n",
        "        _, _, mse = bilstm_model.evaluate(X_test, Y_test, verbose=0)\n",
        "        rmse = np.sqrt(mse)\n",
        "        print(f\"-> BiLSTM RMSE (Volatility Forecast Accuracy): {rmse:.6f}\")\n",
        "\n",
        "\n",
        "        Y_pred_scaled = bilstm_model.predict(X_test, verbose=0)\n",
        "        Y_pred_denorm = target_scaler.inverse_transform(Y_pred_scaled)\n",
        "\n",
        "\n",
        "        Y_pred_denorm = np.maximum(Y_pred_denorm, 1e-9)\n",
        "\n",
        "        predicted_volatilities_mean = np.mean(Y_pred_denorm, axis=0)\n",
        "\n",
        "\n",
        "        historical_returns = features.loc[test_index]\n",
        "        expected_returns_annual = historical_returns.mean().values * ANNUALIZATION_FACTOR\n",
        "\n",
        "\n",
        "        correlation_matrix = historical_returns.corr().values\n",
        "        correlation_matrix[np.isnan(correlation_matrix)] = 0\n",
        "\n",
        "\n",
        "        predicted_sigma = np.sqrt(predicted_volatilities_mean)\n",
        "        D = np.diag(predicted_sigma)\n",
        "\n",
        "        predicted_covariance_matrix = D @ correlation_matrix @ D * ANNUALIZATION_FACTOR\n",
        "\n",
        "\n",
        "        metrics = optimize_portfolio(\n",
        "            expected_returns_annual, predicted_covariance_matrix, TICKERS_LIST, RISK_FREE_RATE\n",
        "        )\n",
        "\n",
        "        metrics['RMSE'] = rmse\n",
        "        metrics['Tickers'] = N_FEATURES_FINAL\n",
        "        all_results[country] = metrics\n",
        "\n",
        "        print(f\"-> Optimization Status: {metrics['Status']}\")\n",
        "        print(f\"-> Predicted Annual Return: {metrics['Return']:.2%}\")\n",
        "        print(f\"-> Predicted Annual Volatility (Risk): {metrics['Volatility']:.2%}\")\n",
        "        print(f\"-> Predicted Sharpe Ratio: {metrics['Sharpe']:.3f}\")\n",
        "        print(f\"-> Top Weights (Min 1%, Max 40%):\\\\n{metrics['Weights']}\")\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "        if metrics['Sharpe'] > best_sharpe and not np.isnan(metrics['Sharpe']):\n",
        "            best_sharpe = metrics['Sharpe']\n",
        "            best_country = country\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\n\\n=============== FINAL COMPARISON OF BEST COUNTRY PORTFOLIOS (DIVERSIFIED) ===============\")\n",
        "    summary_df = pd.DataFrame.from_dict(all_results, orient='index')\n",
        "\n",
        "    summary_df['Return'] = (summary_df['Return'] * 100).map('{:.2f}%'.format)\n",
        "    summary_df['Volatility'] = (summary_df['Volatility'] * 100).map('{:.2f}%'.format)\n",
        "    summary_df['Sharpe'] = summary_df['Sharpe'].map('{:.3f}'.format)\n",
        "    summary_df = summary_df[['Tickers', 'RMSE', 'Return', 'Volatility', 'Sharpe']]\\\n",
        "        .sort_values(by='Sharpe', ascending=False)\n",
        "\n",
        "    print(summary_df.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "    print(f\"\\nConclusion: The country whose portfolio leads to the best Sharpe Ratio is **{best_country}**.\")\n",
        "    print(\"=======================================================================================\\n\")\n",
        "\n",
        "\n",
        "try:\n",
        "    main_analysis()\n",
        "except NameError:\n",
        "    print(\"Please ensure all necessary libraries (yfinance, pandas, numpy, tensorflow, arch, scipy, sklearn) are installed and imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4B_TtGohR3N",
        "outputId": "f9462204-91fc-49ec-8c0b-7a5d7fbc603c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING MULTI-COUNTRY QUANTITATIVE ANALYSIS (DIVERSIFIED) ---\n",
            "\n",
            "1. Downloading and processing data from 2010-01-01 to 2024-12-31...\n",
            "\n",
            "==================== PROCESSING: UK (7 assets) ====================\n",
            "\n",
            "Data prepared. Final Tickers: 7. Test set size: 771.\n",
            "-> BiLSTM RMSE (Volatility Forecast Accuracy): 0.060695\n",
            "-> Optimization Status: Optimization terminated successfully\n",
            "-> Predicted Annual Return: 16.93%\n",
            "-> Predicted Annual Volatility (Risk): 21.04%\n",
            "-> Predicted Sharpe Ratio: 0.709\n",
            "-> Top Weights (Min 1%, Max 40%):\\nNWG.L    0.39\n",
            "HSBA.L   0.38\n",
            "STAN.L   0.19\n",
            "AV.L     0.01\n",
            "LGEN.L   0.01\n",
            "----------------------------------------------------------\n",
            "\n",
            "==================== PROCESSING: France (7 assets) ====================\n",
            "\n",
            "Data prepared. Final Tickers: 7. Test set size: 771.\n",
            "-> BiLSTM RMSE (Volatility Forecast Accuracy): 0.042075\n",
            "-> Optimization Status: Optimization terminated successfully\n",
            "-> Predicted Annual Return: 11.82%\n",
            "-> Predicted Annual Volatility (Risk): 23.90%\n",
            "-> Predicted Sharpe Ratio: 0.411\n",
            "-> Top Weights (Min 1%, Max 40%):\\nCS.PA    0.40\n",
            "SGO.PA   0.40\n",
            "ACA.PA   0.16\n",
            "CA.PA    0.01\n",
            "BNP.PA   0.01\n",
            "----------------------------------------------------------\n",
            "\n",
            "==================== PROCESSING: USA (7 assets) ====================\n",
            "\n",
            "Data prepared. Final Tickers: 7. Test set size: 771.\n",
            "-> BiLSTM RMSE (Volatility Forecast Accuracy): 0.061719\n",
            "-> Optimization Status: Optimization terminated successfully\n",
            "-> Predicted Annual Return: 14.56%\n",
            "-> Predicted Annual Volatility (Risk): 3.47%\n",
            "-> Predicted Sharpe Ratio: 3.620\n",
            "-> Top Weights (Min 1%, Max 40%):\\nMS    0.40\n",
            "AXP   0.40\n",
            "GS    0.16\n",
            "WFC   0.01\n",
            "BAC   0.01\n",
            "----------------------------------------------------------\n",
            "\n",
            "==================== PROCESSING: Australia (7 assets) ====================\n",
            "\n",
            "Data prepared. Final Tickers: 7. Test set size: 771.\n",
            "-> BiLSTM RMSE (Volatility Forecast Accuracy): 0.068306\n",
            "-> Optimization Status: Optimization terminated successfully\n",
            "-> Predicted Annual Return: 14.94%\n",
            "-> Predicted Annual Volatility (Risk): 5.05%\n",
            "-> Predicted Sharpe Ratio: 2.563\n",
            "-> Top Weights (Min 1%, Max 40%):\\nSUN.AX   0.40\n",
            "ANZ.AX   0.40\n",
            "WBC.AX   0.16\n",
            "CBA.AX   0.01\n",
            "NAB.AX   0.01\n",
            "----------------------------------------------------------\n",
            "\n",
            "\n",
            "=============== FINAL COMPARISON OF BEST COUNTRY PORTFOLIOS (DIVERSIFIED) ===============\n",
            "|           | Tickers   | RMSE      | Return   | Volatility   | Sharpe   |\n",
            "|:----------|:----------|:----------|:---------|:-------------|:---------|\n",
            "| USA       | 7         | 0.0617188 | 14.56%   | 3.47%        | 3.62     |\n",
            "| Australia | 7         | 0.0683055 | 14.94%   | 5.05%        | 2.563    |\n",
            "| UK        | 7         | 0.0606949 | 16.93%   | 21.04%       | 0.709    |\n",
            "| France    | 7         | 0.0420753 | 11.82%   | 23.90%       | 0.411    |\n",
            "\n",
            "Conclusion: The country whose portfolio leads to the best Sharpe Ratio is **USA**.\n",
            "=======================================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}